{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\thanhnx\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBERT_model = SentenceTransformer('../model/22k_sample/22k_sample/')\n",
    "sentences = [\"Hey there, are you good ?\" , \"How are you today?\"]\n",
    "vectors = SBERT_model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5722304582595825\n"
     ]
    }
   ],
   "source": [
    "similarity = 1 - spatial.distance.cosine(vectors[0], vectors[1])\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model to directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './model'\n",
    "SBERT_model.save(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-model-archiver\n",
      "  Obtaining dependency information for torch-model-archiver from https://files.pythonhosted.org/packages/9b/20/08047e340f7d136695eec8230eb7eef9fdf5d4d75ddedb146d2b76b5d833/torch_model_archiver-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading torch_model_archiver-0.9.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting enum-compat (from torch-model-archiver)\n",
      "  Downloading enum_compat-0.0.3-py3-none-any.whl (1.3 kB)\n",
      "Downloading torch_model_archiver-0.9.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: enum-compat, torch-model-archiver\n",
      "Successfully installed enum-compat-0.0.3 torch-model-archiver-0.9.0\n"
     ]
    }
   ],
   "source": [
    "# install torch-model-archiver\n",
    "!pip install torch-model-archiver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create mar file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!torch-model-archiver --model-name sbert --version 1.0 --serialized-file model/model.safetensors --handler run_handler.py --extra-files \"model/config.json,model/vocab.txt\" --export-path .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "docker build -t ptserve-sbert:v1\n",
    "docker run -rm -it -p 3000:8000 ptserve-sbert:v1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5722305470510088\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "sbert_api = \"http://localhost:3000\"\n",
    "sentences = [\"Hey there, are you good ?\" , \"How are you today?\"]\n",
    "response = requests.post(sbert_api + '/predictions/SBERT',data = {'data' : json.dumps({'queries' : sentences})})\n",
    "if response.status_code:\n",
    "    vectors = response.json()\n",
    "    similarity = 1 - spatial.distance.cosine(vectors[0], vectors[1])\n",
    "    print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load text embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ebd = json.load(open('../text_ebd.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "for x in text_ebd:\n",
    "    if x['label'] not in embeddings:\n",
    "        embeddings[x['label']] = []\n",
    "    embeddings[x['label']].append(x['embedding_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "my_skill = \"python , machine learning , deep learning\"\n",
    "response = requests.post(sbert_api + '/predictions/SBERT',data = {'data' : json.dumps({'queries' : [my_skill]})})\n",
    "result = {}       \n",
    "if response.status_code:\n",
    "    my_skill_vector = response.json()[0]\n",
    "    # calculate mean similarity score over labels\n",
    "    \n",
    "    for label in embeddings:\n",
    "        similarity_scores = []\n",
    "        for embed in embeddings[label]:\n",
    "            similarity_scores.append(1- spatial.distance.cosine(my_skill_vector,embed))\n",
    "        result[label] = np.mean(similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AI Engineer': 0.3174099713230376, 'Data Scientist': 0.260975348115142, 'System Engineer': 0.24309589227261694, 'Data Engineer': 0.20026894576905616, 'ERP Engineer': 0.19408055682212033, 'product manager': 0.18510211040041114, 'project management': 0.18031327409847833, 'IT Consultant': 0.17627145356397053, 'Data Analyst': 0.17301229549634933, 'IT Lead': 0.16445666113500776, 'Data Architect': 0.15007072930680554, 'QA-QC': 0.14024028137735015, 'Designer': 0.13677837792050782, 'business analyst': 0.1355498116775852, 'product owner': 0.1279543394130478, 'embedded engineer': 0.12150634112031009, 'System Admin': 0.10302775103177542, 'Solution Architect': 0.09668156490867848, 'Tester': 0.09646868402118336, 'DevOps Engineer': 0.06966344768696633, 'game developer': 0.0645053750107425, 'back-end developer': 0.05440490205038706, 'full-stack developer': 0.038860542154955165, 'front-end developer': 0.015493780341919387, 'mobile developer': -0.0034063260511167925}\n"
     ]
    }
   ],
   "source": [
    "# sort the result\n",
    "result = {k: v for k, v in sorted(result.items(), key=lambda item: item[1],reverse=True)}\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thanhnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
